{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAND PRICE PREDICTION APP USING AWS SAGEMAKER'S IN-BUILT XGBOOST  - End-to-End\n",
    "We will build a Land Price Prediction App to help people looking to buy land in Cameroon, get the expected price of land per quartier they intend to buy land from.\n",
    "The following steps will be taken:\n",
    "- I)   PROBLEM STATEMENT:\n",
    "\n",
    "Many people in Cameroon want to buy lands and they have trouble getting information on what to expect as price per square metre for the quartier they want to buy the land from.They also want to be able to consult the prices of several quartiers before making their final choice.\n",
    "This is a difficult process in Cameroon as it will mean these people who want to buy lands will have to go about making many phone calls to people asking them the price of land in those quartiers.\n",
    "So the objective is to scrape the data already available on the biggest Classified adds website in Cameroon (Jumia Cameroon) https://www.jumia.cm/en/land-plots\n",
    "\n",
    "This data will be cleaned and trained using the in-built XGBoost Algorithm on AWS Sagemaker, and an endpoint will be created in AWS ,which wll be used to make predictions when given the inputs like \n",
    "- The Quartier the customer wants to buy land from\n",
    "- The size of the land the customer intends to buy (in metres square)\n",
    "- And the output of the model will be the predicted Price per metres square for the Quartier the customer requested.\n",
    "\n",
    "\n",
    "- II)   SCRAPING THE DATA:\n",
    "\n",
    "Scrape the data from a Classified ads website, where people post lands for sale per quartier in Cameroon.They typically type in the price per metres square and the total area of the land availlable for sale.\n",
    "- III)  PERFORM EXPLORATORY DATA ANALYSIS \n",
    "\n",
    "Inspect the data to validate the quality of the data scraped from the classified ads website. Analyse the distribution of missing values, outliers and gain other relevant insights from the model\n",
    "- IV) DO FEATURE ENGINEERING & SELECTION\n",
    "\n",
    "Handle the mising values, outliers and do the necessary transformations which will ensure the data is well suited for the machine learning model.And also to maximise the insights gotten from the Exploratory Data Analysis phase.\n",
    "- V)  BUILD,TRAIN AND DEPLOY THE MODEL IN SAGEMAKER\n",
    "\n",
    "The Boto3 Container will be used to create the S3 buckets to store the preprocessed dataset.The Sagemaker's inbuilt XGBoost algorithm, will be built, trained and deployed.Including the use of optimal hyperparameters to get the best results for the RMSE( Root Mean Squared Error).An Endpoint will be created after the model is built.\n",
    "The Endpoint created awill be used to predict the price per metre square when the inputs of \"Quartier\" and \"Land size\" are fed to the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V) BUILD,TRAIN AND DEPLOY THE MODEL IN SAGEMAKER\n",
    "We will perform the following tasks, in order to successully scrape the data we need\n",
    "- a.) Importing the necessary Libraries and create S3 bucket\n",
    "- b.) Download the train and test data and store in S3\n",
    "- c.) Build and Train the Inbuilt XGBoost model\n",
    "- d.) Deploy the model to an Endpoint\n",
    "- e.) Test the predictions\n",
    "- f.) Delete the Endpoint\n",
    "- g.) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.) Importing all the necessary libraries and creating S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.session import s3_input, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'landpriceapp' # <--- Give this a unique name, since there can be no 02 bucket names in AWS\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://landpriceapp/xgboost-inbuilt-algo/output\n"
     ]
    }
   ],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "prefix = 'xgboost-inbuilt-algo'\n",
    "output_path ='s3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.) Download the train and test data and store in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded train_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "#Importing the train dataset\n",
    "try:\n",
    "    urllib.request.urlretrieve (\"https://raw.githubusercontent.com/Bandolo/AWS-Machine-Learning-Projects/main/LandPriceApp-XGBoost-Sagemaker/train_clean.csv\", \"train_clean.csv\")\n",
    "    print('Success: downloaded train_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "    train_clean = pd.read_csv('./train_clean.csv',index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded train_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "#Importing the test dataset\n",
    "try:\n",
    "    urllib.request.urlretrieve (\"https://raw.githubusercontent.com/Bandolo/AWS-Machine-Learning-Projects/main/LandPriceApp-XGBoost-Sagemaker/test_clean.csv\", \"test_clean.csv\")\n",
    "    print('Success: downloaded train_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "    train_clean = pd.read_csv('./test_clean.csv',index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695, 24)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Price_log  Awae  Bastos  Bonaberi  Bonamoussadi  Douala  Japoma  \\\n",
      "Area                                                                        \n",
      "10000.0    8.987197     0       0         0             0       1       0   \n",
      "200000.0   9.615805     0       0         0             0       0       0   \n",
      "500.0     10.915088     0       0         0             0       0       0   \n",
      "310.0     10.463103     0       0         0             0       0       0   \n",
      "1000.0    10.126631     0       0         0             0       0       1   \n",
      "\n",
      "          Kotto  Kribi  Lendi  ...  Mfou  Nkoabang  Odza  PK12  PK16  PK21  \\\n",
      "Area                           ...                                           \n",
      "10000.0       0      0      0  ...     0         0     0     0     0     0   \n",
      "200000.0      0      0      0  ...     0         0     0     0     0     0   \n",
      "500.0         0      0      0  ...     0         0     0     0     0     0   \n",
      "310.0         0      0      0  ...     0         0     0     0     0     0   \n",
      "1000.0        0      0      0  ...     0         0     0     0     0     0   \n",
      "\n",
      "          Soa  Village  YaoundÃ©  Yassa  \n",
      "Area                                    \n",
      "10000.0     0        0        0      0  \n",
      "200000.0    0        0        0      0  \n",
      "500.0       0        0        0      1  \n",
      "310.0       0        1        0      0  \n",
      "1000.0      0        0        0      0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Price_log  Awae  Bastos  Bonaberi  Bonamoussadi  Douala  Japoma  \\\n",
      "Area                                                                      \n",
      "1800.0  11.512925     0       0         0             0       0       1   \n",
      "9000.0   8.160518     0       0         0             0       0       0   \n",
      "3000.0   9.740969     0       0         0             0       0       0   \n",
      "500.0    9.798127     0       0         0             0       0       0   \n",
      "500.0   11.002100     0       0         0             0       0       0   \n",
      "\n",
      "        Kotto  Kribi  Lendi  ...  Mfou  Nkoabang  Odza  PK12  PK16  PK21  Soa  \\\n",
      "Area                         ...                                                \n",
      "1800.0      0      0      0  ...     0         0     0     0     0     0    0   \n",
      "9000.0      0      0      1  ...     0         0     0     0     0     0    0   \n",
      "3000.0      0      0      0  ...     0         0     0     0     0     0    0   \n",
      "500.0       0      0      0  ...     0         0     1     0     0     0    0   \n",
      "500.0       0      0      0  ...     0         0     0     0     0     0    0   \n",
      "\n",
      "        Village  YaoundÃ©  Yassa  \n",
      "Area                             \n",
      "1800.0        0        0      0  \n",
      "9000.0        0        0      0  \n",
      "3000.0        0        0      1  \n",
      "500.0         0        0      0  \n",
      "500.0         0        0      0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving Train And Test Into Buckets\n",
    "## We start with Train Data\n",
    "import os\n",
    "pd.concat([train['Price_log'], train.drop(['Price_log'], \n",
    "                                                axis=1)], \n",
    "                                                axis=1).to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Into Buckets\n",
    "pd.concat([test['Price_log'], test.drop(['Price_log'], \n",
    "                                              axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = sagemaker.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.) Build and Train the Inbuilt XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"0.3\",\n",
    "        \"min_child_weight\":\"7\",\n",
    "        \"subsample\":\"1\",\n",
    "        \"objective\":\"reg:linear\",\n",
    "        \"num_round\":50\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=output_path,\n",
    "                                          use_spot_instances=True,\n",
    "                                          max_run=300,\n",
    "                                          max_wait=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-10 14:57:08 Starting - Starting the training job...\n",
      "2021-12-10 14:57:15 Starting - Launching requested ML instancesProfilerReport-1639148228: InProgress\n",
      "......\n",
      "2021-12-10 14:58:26 Starting - Preparing the instances for training.........\n",
      "2021-12-10 15:00:07 Downloading - Downloading input data\n",
      "2021-12-10 15:00:07 Training - Downloading the training image.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-12-10:15:00:10:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-12-10:15:00:10:INFO] File size need to be processed in the node: 0.21mb. Available memory size in the node: 23762.52mb\u001b[0m\n",
      "\u001b[34m[2021-12-10:15:00:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:00:10] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:00:10] 2777x23 matrix with 63871 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-12-10:15:00:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:00:10] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:00:10] 695x23 matrix with 15985 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:7.73262#011validation-rmse:7.78948\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:6.23128#011validation-rmse:6.28218\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:5.03875#011validation-rmse:5.0888\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:4.09512#011validation-rmse:4.1376\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:3.35267#011validation-rmse:3.39637\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:2.77319#011validation-rmse:2.81788\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:2.32657#011validation-rmse:2.36366\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:1.98683#011validation-rmse:2.02042\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:1.73412#011validation-rmse:1.76243\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:1.54916#011validation-rmse:1.56977\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:1.41727#011validation-rmse:1.43009\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:1.325#011validation-rmse:1.33347\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:1.26135#011validation-rmse:1.26323\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:1.2181#011validation-rmse:1.21579\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:1.1889#011validation-rmse:1.18063\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:1.16915#011validation-rmse:1.15757\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:1.1559#011validation-rmse:1.14214\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:1.14677#011validation-rmse:1.12989\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:1.1405#011validation-rmse:1.12219\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:1.13588#011validation-rmse:1.11711\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:1.13264#011validation-rmse:1.11319\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:1.13031#011validation-rmse:1.10897\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:1.12852#011validation-rmse:1.10704\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:1.12706#011validation-rmse:1.10563\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:1.12597#011validation-rmse:1.10461\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:1.12505#011validation-rmse:1.10262\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:1.12428#011validation-rmse:1.1019\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:1.12366#011validation-rmse:1.10137\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:1.12313#011validation-rmse:1.10009\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:1.12266#011validation-rmse:1.09983\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:1.12224#011validation-rmse:1.09972\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:1.12188#011validation-rmse:1.09962\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:1.12159#011validation-rmse:1.09952\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:1.12129#011validation-rmse:1.09908\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:1.12103#011validation-rmse:1.09857\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:1.12081#011validation-rmse:1.09859\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:1.1206#011validation-rmse:1.09835\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:1.12042#011validation-rmse:1.09789\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:1.12026#011validation-rmse:1.09783\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:1.12012#011validation-rmse:1.09797\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:1.11999#011validation-rmse:1.09762\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:1.11988#011validation-rmse:1.09769\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:1.11978#011validation-rmse:1.09768\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:1.11978#011validation-rmse:1.09767\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:1.11978#011validation-rmse:1.09767\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:1.11978#011validation-rmse:1.09766\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:1.11978#011validation-rmse:1.09766\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:1.11978#011validation-rmse:1.09766\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:1.11978#011validation-rmse:1.09765\u001b[0m\n",
      "\u001b[34m[15:00:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:1.11978#011validation-rmse:1.09765\u001b[0m\n",
      "\n",
      "2021-12-10 15:00:27 Uploading - Uploading generated training model\n",
      "2021-12-10 15:00:27 Completed - Training job completed\n",
      "Training seconds: 33\n",
      "Billable seconds: 17\n",
      "Managed Spot Training savings: 48.5%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': s3_input_train,'validation': s3_input_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.) Deploy the model to an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.) Test the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695,)\n"
     ]
    }
   ],
   "source": [
    "#from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "test_data_array = test.drop(['Price_log'], axis=1).values #load the data into an array\n",
    "#xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = CSVSerializer() # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41550922,  9.58652115, 10.30050278, 10.1236887 , 10.1236887 ,\n",
       "        9.02184963,  9.67544365,  9.67544365, 10.1236887 ,  8.48962975])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_array[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_log</th>\n",
       "      <th>Awae</th>\n",
       "      <th>Bastos</th>\n",
       "      <th>Bonaberi</th>\n",
       "      <th>Bonamoussadi</th>\n",
       "      <th>Douala</th>\n",
       "      <th>Japoma</th>\n",
       "      <th>Kotto</th>\n",
       "      <th>Kribi</th>\n",
       "      <th>Lendi</th>\n",
       "      <th>...</th>\n",
       "      <th>Mfou</th>\n",
       "      <th>Nkoabang</th>\n",
       "      <th>Odza</th>\n",
       "      <th>PK12</th>\n",
       "      <th>PK16</th>\n",
       "      <th>PK21</th>\n",
       "      <th>Soa</th>\n",
       "      <th>Village</th>\n",
       "      <th>YaoundÃ©</th>\n",
       "      <th>Yassa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1800.0</th>\n",
       "      <td>11.512925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000.0</th>\n",
       "      <td>8.160518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000.0</th>\n",
       "      <td>9.740969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>9.798127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>11.002100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>8.987197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300.0</th>\n",
       "      <td>9.903488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000.0</th>\n",
       "      <td>11.082143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783.0</th>\n",
       "      <td>10.126631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>8.853665</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Price_log  Awae  Bastos  Bonaberi  Bonamoussadi  Douala  Japoma  \\\n",
       "Area                                                                       \n",
       "1800.0   11.512925     0       0         0             0       0       1   \n",
       "9000.0    8.160518     0       0         0             0       0       0   \n",
       "3000.0    9.740969     0       0         0             0       0       0   \n",
       "500.0     9.798127     0       0         0             0       0       0   \n",
       "500.0    11.002100     0       0         0             0       0       0   \n",
       "10000.0   8.987197     0       0         0             0       1       0   \n",
       "300.0     9.903488     0       0         0             0       0       0   \n",
       "2000.0   11.082143     0       0         0             0       0       0   \n",
       "783.0    10.126631     0       0         0             0       0       0   \n",
       "500.0     8.853665     0       0         0             0       0       0   \n",
       "\n",
       "         Kotto  Kribi  Lendi  ...  Mfou  Nkoabang  Odza  PK12  PK16  PK21  \\\n",
       "Area                          ...                                           \n",
       "1800.0       0      0      0  ...     0         0     0     0     0     0   \n",
       "9000.0       0      0      1  ...     0         0     0     0     0     0   \n",
       "3000.0       0      0      0  ...     0         0     0     0     0     0   \n",
       "500.0        0      0      0  ...     0         0     1     0     0     0   \n",
       "500.0        0      0      0  ...     0         0     0     0     0     0   \n",
       "10000.0      0      0      0  ...     0         0     0     0     0     0   \n",
       "300.0        0      0      0  ...     0         0     0     0     0     0   \n",
       "2000.0       0      0      0  ...     0         0     0     0     0     0   \n",
       "783.0        0      0      0  ...     0         0     1     0     0     0   \n",
       "500.0        0      0      0  ...     1         0     0     0     0     0   \n",
       "\n",
       "         Soa  Village  YaoundÃ©  Yassa  \n",
       "Area                                   \n",
       "1800.0     0        0        0      0  \n",
       "9000.0     0        0        0      0  \n",
       "3000.0     0        0        0      1  \n",
       "500.0      0        0        0      0  \n",
       "500.0      0        0        0      0  \n",
       "10000.0    0        0        0      0  \n",
       "300.0      0        0        1      0  \n",
       "2000.0     0        0        1      0  \n",
       "783.0      0        0        0      0  \n",
       "500.0      0        0        0      0  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f.) Deleting The Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sagemaker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ecd069109aa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msagemaker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_predictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbucket_to_delete\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m's3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbucket_to_delete\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sagemaker' is not defined"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations!!! You just built an end-to-end machine learning app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g.)Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the house prices have a very high variance the model is RMSE cannot go very low.\n",
    "There are options to improve the model, like replacing all the house prices per Location with just the median price per location.That way the model will have less varaince.\n",
    "\n",
    "Feel free to use any resources here to improve on the model's performence.\n",
    "\n",
    "Wish you Good Data Luck!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wish you Good Data Luck!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
